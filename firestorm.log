DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:154)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, about=, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, about=, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, about=, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:154)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:154)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:454)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:425)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:502)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3420)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3416)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3258)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:470)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:213)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:210)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
	at com.hbase.api.HadoopTest.main(HadoopTest.java:18)
WARN main org.apache.hadoop.util.Shell - Did not find winutils.exe: {}
java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:534)
	at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:555)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:578)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:675)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3420)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3416)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3258)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:470)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:213)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:210)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
	at com.hbase.api.HadoopTest.main(HadoopTest.java:18)
Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:454)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:425)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:502)
	... 12 more
DEBUG main org.apache.hadoop.util.Shell - Failed to find winutils.exe
java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:534)
	at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:555)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:578)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:675)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3420)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3416)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3258)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:470)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:213)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:210)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
	at com.hbase.api.HadoopTest.main(HadoopTest.java:18)
Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:454)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:425)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:502)
	... 12 more
DEBUG main org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
DEBUG main org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
DEBUG main org.apache.hadoop.fs.FileSystem - Loading filesystems
DEBUG main org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /D:/repository/repository/org/apache/hadoop/hadoop-common/2.9.2/hadoop-common-2.9.2.jar
DEBUG main org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /D:/repository/repository/org/apache/hadoop/hadoop-common/2.9.2/hadoop-common-2.9.2.jar
DEBUG main org.apache.hadoop.fs.FileSystem - ftp:// = class org.apache.hadoop.fs.ftp.FTPFileSystem from /D:/repository/repository/org/apache/hadoop/hadoop-common/2.9.2/hadoop-common-2.9.2.jar
DEBUG main org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /D:/repository/repository/org/apache/hadoop/hadoop-common/2.9.2/hadoop-common-2.9.2.jar
DEBUG main org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /D:/repository/repository/org/apache/hadoop/hadoop-common/2.9.2/hadoop-common-2.9.2.jar
DEBUG main org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /D:/repository/repository/org/apache/hadoop/hadoop-common/2.9.2/hadoop-common-2.9.2.jar
DEBUG main org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /D:/repository/repository/org/apache/hadoop/hadoop-hdfs-client/2.9.2/hadoop-hdfs-client-2.9.2.jar
DEBUG main org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /D:/repository/repository/org/apache/hadoop/hadoop-hdfs-client/2.9.2/hadoop-hdfs-client-2.9.2.jar
DEBUG main org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /D:/repository/repository/org/apache/hadoop/hadoop-hdfs-client/2.9.2/hadoop-hdfs-client-2.9.2.jar
DEBUG main org.apache.hadoop.fs.FileSystem - hftp:// = class org.apache.hadoop.hdfs.web.HftpFileSystem from /D:/repository/repository/org/apache/hadoop/hadoop-hdfs-client/2.9.2/hadoop-hdfs-client-2.9.2.jar
DEBUG main org.apache.hadoop.fs.FileSystem - hsftp:// = class org.apache.hadoop.hdfs.web.HsftpFileSystem from /D:/repository/repository/org/apache/hadoop/hadoop-hdfs-client/2.9.2/hadoop-hdfs-client-2.9.2.jar
DEBUG main org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
DEBUG main org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
DEBUG main org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
DEBUG main org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=D:\Java\jdk1.8.0_112\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;.;D:\oracle\oracle\product\11.2.0\dbhome_1\BIN;D:\Java\jdk1.8.0_112\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;%CATALINA_HOME%\lib;%CATALINA_HOME%\bin;D:\mysql-5.5.59-winx64\mysql-5.5.59-winx64\BIN;E:\TortoiseSVN\bin;D:\apache-maven-3.2.5\bin;E:\Git\cmd;.
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@16293aa2
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@59662a0b
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.hdfs.DFSClient - /testhdfs: masked=rwxr-xr-x
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to /47.110.76.197:9000
DEBUG IPC Client (306980751) connection to /47.110.76.197:9000 from root org.apache.hadoop.ipc.Client - IPC Client (306980751) connection to /47.110.76.197:9000 from root: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (306980751) connection to /47.110.76.197:9000 from root sending #0 org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs
DEBUG IPC Client (306980751) connection to /47.110.76.197:9000 from root org.apache.hadoop.ipc.Client - IPC Client (306980751) connection to /47.110.76.197:9000 from root got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: mkdirs took 83ms
DEBUG shutdown-hook-0 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@59662a0b
DEBUG shutdown-hook-0 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@59662a0b
DEBUG shutdown-hook-0 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@59662a0b
DEBUG shutdown-hook-0 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (306980751) connection to /47.110.76.197:9000 from root org.apache.hadoop.ipc.Client - IPC Client (306980751) connection to /47.110.76.197:9000 from root: closed
DEBUG IPC Client (306980751) connection to /47.110.76.197:9000 from root org.apache.hadoop.ipc.Client - IPC Client (306980751) connection to /47.110.76.197:9000 from root: stopped, remaining connections 0
DEBUG Thread-2 org.apache.hadoop.util.ShutdownHookManager - Completed shutdown in 0.102 seconds; Timeouts: 0
DEBUG Thread-2 org.apache.hadoop.util.ShutdownHookManager - ShutdownHookManger completed shutdown.
DEBUG main org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
DEBUG main org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
DEBUG main org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
DEBUG main org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
DEBUG main org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
DEBUG main org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
DEBUG main org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
DEBUG main org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
DEBUG main org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
DEBUG main org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
DEBUG main org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
DEBUG main org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
DEBUG main org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
DEBUG main org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
